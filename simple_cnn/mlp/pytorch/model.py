import torch
from torch import nn

# TOOD: decide whether you want to make a class
# or simply call nn.sequential

# not that it really matters
# class MLP(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.flatten = nn.Flatten()
#         self.linear_relu_stack = nn.Sequential(

#         )