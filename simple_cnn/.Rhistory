extract_fun = function(temp, data_path) {
unzip2(temp, exdir = data_path)
unzip2(fs::path(data_path, "train_imgs.zip"), exdir = data_path)
unzip2(fs::path(data_path, "test_imgs.zip"), exdir = data_path)
}
)
# variavel resposta -------------------------------------------------
if(split == "train") {
self$images <- readr::read_csv(fs::path(data_path, "train.csv"), col_types = c("cn"))
if(!is.null(indexes)) self$images <- self$images[indexes, ]
self$.path <- file.path(data_path, "train_imgs")
} else if(split == "submission") {
self$images <- readr::read_csv(fs::path(data_path, "example_submition.csv"), col_types = c("cn"))
self$images$corr <- NA_real_
self$.path <- file.path(data_path, "test_imgs")
}
},
.getitem = function(index) {
force(index)
sample <- self$images[index, ]
id <- sample$id
x <- torchvision::base_loader(file.path(self$.path, paste0(sample$id, ".png")))
x <- torchvision::transform_to_tensor(x) %>% torchvision::transform_rgb_to_grayscale()
if (!is.null(self$transform))
x <- self$transform(x)
# y <- torch::torch_scalar_tensor(sample$corr)
# if (!is.null(self$target_transform))
#   y <- self$target_transform(y)
return(list(x = x, id = id))
},
.length = function() {
nrow(self$images)
}
)
train_mlr3torch_ds <- guess_the_correlation_dataset_(
root = root,
transform = function(img) crop_axes(img),
indexes = trn_idx,
download = TRUE # change if necessary
)
valid_mlr3torch_ds <- guess_the_correlation_dataset_(
root = root,
transform = function(img) crop_axes(img),
indexes = val_idx,
download = FALSE
)
test_mlr3torch_ds <- guess_the_correlation_dataset_(
root = root,
transform = function(img) crop_axes(img),
indexes = tst_idx,
download = FALSE
)
rm(list = ls())
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
dd_gtcorr = as_data_descriptor(train_mlr3torch_ds,
dataset_shapes = list(x = c(NA, 16900L))
)
rm(list = ls())
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
rm(list = ls())
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
rm(list = ls())
source("~/mlr3_hiwi/benchmark_experiments/simple_cnn/main.R", echo=TRUE)
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
dd_gtcorr
dd_gtcorr
tsk("iris")
tsk("mnist")
tsk("mnist")$data
tsk_mnist = tsk("mnist")
tsk_mnist$data()
lt = as_lazy_tensor(dd)
lt = as_lazy_tensor(dd_gtcorr)
lt
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
library(mlr3torch)
learner_mlp = lrn("classif.mlp",
activation = nn_relu,
neurons = c(20, 20),
batch_size = 16,
epochs = 50,
device = "cpu",
optimizer = t_opt("adam", lr = 0.1),
loss = t_loss("cross_entropy"),
callbacks = t_clbk("history"),
measures_valid = msrs(c("classif.logloss", "classif.ce")),
measures_train = msrs(c("classif.acc")),
predict_type = "prob"
)
rr = resample(
task = tsk("iris"),
learner = learner_mlp,
resampling = rsmp("holdout")
)
architecture = po("torch_ingress_num") %>>%
po("nn_linear", out_features = 20) %>>%
po("nn_relu") %>>%
po("nn_head")
graph_mlp = architecture %>>%
po("torch_loss", loss = t_loss("cross_entropy")) %>>%
po("torch_optimizer", optimizer = t_opt("adam", lr = 0.1)) %>>%
po("torch_callbacks", callbacks = t_clbk("history")) %>>%
po("torch_model_classif", batch_size = 16, epochs = 50, device = "cpu")
graph_mlp
library(mlr3torch)
learner_mlp = lrn("classif.mlp",
activation = nn_relu,
neurons = c(20, 20),
batch_size = 16,
epochs = 50,
device = "cpu",
optimizer = t_opt("adam", lr = 0.1),
loss = t_loss("cross_entropy"),
callbacks = t_clbk("history"),
measures_valid = msrs(c("classif.logloss", "classif.ce")),
measures_train = msrs(c("classif.acc")),
predict_type = "prob"
)
rr = resample(
task = tsk("iris"),
learner = learner_mlp,
resampling = rsmp("holdout")
)
rr
# architecture = po("torch_ingress_num") %>>%
#   po("nn_linear", out_features = 20) %>>%
#   po("nn_relu") %>>%
#   po("nn_head")
#
# graph_mlp = architecture %>>%
#   po("torch_loss", loss = t_loss("cross_entropy")) %>>%
#   po("torch_optimizer", optimizer = t_opt("adam", lr = 0.1)) %>>%
#   po("torch_callbacks", callbacks = t_clbk("history")) %>>%
#   po("torch_model_classif", batch_size = 16, epochs = 50, device = "cpu")
#
# graph_lrn = as_learner(graph_mlp)
# graph_lrn$id = "graph_mlp"
#
# resample(
#   task = tsk("iris"),
#   learner = graph_lrn,
#   resampling = rsmp("holdout")
# )
task
rr
rr
rr$score()
architecture = po("torch_ingress_num") %>>%
po("nn_linear", out_features = 20) %>>%
po("nn_relu") %>>%
po("nn_head")
graph_mlp = architecture %>>%
po("torch_loss", loss = t_loss("cross_entropy")) %>>%
po("torch_optimizer", optimizer = t_opt("adam", lr = 0.1)) %>>%
po("torch_callbacks", callbacks = t_clbk("history")) %>>%
po("torch_model_classif", batch_size = 16, epochs = 50, device = "cpu")
graph_lrn = as_learner(graph_mlp)
graph_lrn$id = "graph_mlp"
rr_iris = resample(
task = tsk("iris"),
learner = graph_lrn,
resampling = rsmp("holdout")
)
rr_iris$score()
tsk_iris = tsk("iris")
tsk_iris
tsk_iris$col_info
tsk_mnist = tsk("mnist")
tsk_mnist
tsk_mnist$data()
pak::pak("mlr-org/mlr3torch")
rm(list = ls())
library(mlr3torch)
learner_mlp = lrn("classif.mlp",
activation = nn_relu,
neurons = c(20, 20),
batch_size = 16,
epochs = 50,
device = "cpu",
optimizer = t_opt("adam", lr = 0.1),
loss = t_loss("cross_entropy"),
callbacks = t_clbk("history"),
measures_valid = msrs(c("classif.logloss", "classif.ce")),
measures_train = msrs(c("classif.acc")),
predict_type = "prob"
)
rr = resample(
task = tsk("iris"),
learner = learner_mlp,
resampling = rsmp("holdout")
)
rr$score()
architecture = po("torch_ingress_num") %>>%
po("nn_linear", out_features = 20) %>>%
po("nn_relu") %>>%
po("nn_head")
graph_mlp = architecture %>>%
po("torch_loss", loss = t_loss("cross_entropy")) %>>%
po("torch_optimizer", optimizer = t_opt("adam", lr = 0.1)) %>>%
po("torch_callbacks", callbacks = t_clbk("history")) %>>%
po("torch_model_classif", batch_size = 16, epochs = 50, device = "cpu")
graph_lrn = as_learner(graph_mlp)
graph_lrn$id = "graph_mlp"
rr_iris = resample(
task = tsk("iris"),
learner = graph_lrn,
resampling = rsmp("holdout")
)
rr_iris$score()
tsk_mnist = tsk("mnist")
tsk_mnist
library(here)
# source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
# start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
# start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
source(here("simple_cnn", "set_up_data.R"))
# start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
train_mlr3torch_ds
train_responses
lt = as_lazy_tensor(dd_gtcorr)
# TODO: get the y var
library(data.table)
train_responses = fread(here("simple_cnn", "data/correlation/guess-the-correlation/train_responses.csv"))
# simply cbinding the lazy tensor seems slow and the print output is... strange
dt_train = cbind(train_responses, x = lt)
# print(head(dt_train))
DataBackendDataTable$new(data = dt_train, primary_key = "..id")
dt_train
# print(head(dt_train))
DataBackendDataTable$new(data = dt_train, primary_key = "id")
# print(head(dt_train))
backend = DataBackendDataTable$new(data = dt_train, primary_key = "id")
tsk_gtcorr = TaskRegr$new(id = "guess_the_corr", backend = backend, target = "corr")
dt_train
lt
lt[1]
lt[[1]]
lt = lazy_tensor(dd_gtcorr)
lt
lt[1]
lt[[1]]
lt = lazy_tensor(dd_gtcorr)
# TODO: get the y var
library(data.table)
train_responses = fread(here("simple_cnn", "data/correlation/guess-the-correlation/train_responses.csv"))
# simply cbinding the lazy tensor seems slow and the print output is... strange
dt_train = cbind(train_responses, x = lt)
dt_train
dd_gtcorr
dd_gtcorr = as_data_descriptor(train_mlr3torch_ds,
dataset_shapes = list(x = c(NA, 130, 130))
)
lt = lazy_tensor(dd_gtcorr)
lt
# TODO: get the y var
library(data.table)
train_responses = fread(here("simple_cnn", "data/correlation/guess-the-correlation/train_responses.csv"))
# simply cbinding the lazy tensor seems slow and the print output is... strange
dt_train = cbind(train_responses, x = lt)
# print(head(dt_train))
backend = DataBackendDataTable$new(data = dt_train, primary_key = "id")
tsk_gtcorr = TaskRegr$new(id = "guess_the_corr", backend = backend, target = "corr")
rm(list = ls())
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
# start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
rm(list = ls())
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
# start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
dd_gtcorr = as_data_descriptor(train_mlr3torch_ds,
dataset_shapes = list(x = c(NA, 130, 130))
)
dd_gtcorr
lt = lazy_tensor(dd_gtcorr)
lt
library(data.table)
data.table(y = runif(10000), x = lt)
tsk_regr = as_task_regr(data.table(y = runif(10000), x = lt), target = "y")
tsk_regr
tsk_regr$head
tsk_regr$head()
lt = lazy_tensor(dd_gtcorr)
library(data.table)
train_responses = fread(here("simple_cnn", "data/correlation/guess-the-correlation/train_responses.csv"))
# here, x is a list column
dt_train = cbind(train_responses, x = lt)
dt_train
train_responses
dt_train
train_responses
?cbind
class(dt_train)
dt_train = data.table(corr = train_responses[["corr"]], x = lt)
dt_train
data.table(y = runif(10000), x = lt)
train_responses[["corr"]]
dt_train = data.table(corr = train_responses[["corr"]], x = lt)
dt_train = data.table(corr = train_responses[["corr"]], x = lt)
dt_train
class(lt)
class(dt_train$x)
train_responses = fread(here("simple_cnn", "data/correlation/guess-the-correlation/train_responses.csv"))
train_responses
data.table(y = runif(10000), x = lt)
tsk_gtcorr = as_task_regr(data.table(corr = train_responses[["corr"]], x = lt), target = "corr")
tsk_gtcorr = as_task_regr(data.table(corr = train_responses$corr, x = lt), target = "corr")
train_responses[["corr"]]
typeof(train_responses[["corr"]])
y = runif(10000)
typeof(y)
head(y)
train_responses[["corr"]] |> typeof()
train_responses[["corr"]]
rm(list = ls())
library(here)
source(here("simple_cnn", "set_up_data.R"))
# start_time_torch <- proc.time()
# source("learner_torch.R")
# source("train_torch.R")
# # source("predict_torch.R")
# elapsed_time_torch <- proc.time() - start_time_torch
# start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "learner_mlr3torch.R"))
source(here("simple_cnn", "train_mlr3torch.R"))
lt
length(train_responses)
nrow(train_responses)
nrow(lt)
length(lt)
dt_train = data.table(corr = train_responses[["corr"]][1:length(lt)], x = lt)
#
dt_train = data.table(corr = train_responses[["corr"]][1:length(lt)], x = lt)
#
tsk_gtcorr = as_task_regr(dt_train, target = "corr")
tsk_gtcorr
rep
?rep
rep(lt)
rep(lt, times = 2)
lt_rep = rep(lt, times = 2)
lt_rep
View(lt_rep)
library(here)
# source(here("simple_cnn", "download_data.R"))
# start_time_torch <- proc.time()
# source(here("simple_cnn", "torch", "set_up_data.R"))
# source(here("simple_cnn", "torch", "instantiate_learner.R"))
# source(here("simple_cnn", "torch", "train_learner.R"))
# source(here("simple_cnn", "torch", "evaluate_learner.R"))
# elapsed_time_torch <- proc.time() - start_time_torch
# print(elapsed_time_torch)
source(here("simple_cnn", "download_data.R"))
start_time_mlr3torch <- proc.time()
source(here("simple_cnn", "mlr3torch", "set_up_data.R"))
source(here("simple_cnn", "mlr3torch", "instantiate_learner.R"))
source(here("simple_cnn", "mlr3torch", "train_learner.R"))
train_mlr3torch_ds
tsk_gtcoor
tsk_gtcorr
tsk_gtcorr$data()
learner_mlr3torch_mlp$train(tsk_gtcorr)
train_mlr3torch_ds
train_mlr3torch_ds$.getitem()
train_mlr3torch_ds$.getitem(1)
# create data descriptor
dd_gtcorr = as_data_descriptor(train_mlr3torch_ds, list(x = c(NA, 130, 130)))
# create lazy tensor
lt = lazy_tensor(dd_gtcorr)
# construct the data.table for training
dt_train = data.table(corr = train_responses[["corr"]][trn_idx], x = lt)
dt_train
tsk_gtcorr = as_task_regr(dt_train, target = "corr")
tsk_gtcoor
tsk_gtcorr
learner_mlr3torch_mlp$train(tsk_gtcorr)
library(here)
source(here("simple_cnn", "download_data.R"))
start_time_mlr3torch = proc.time()
source(here("simple_cnn", "mlp", "mlr3torch", "set_up_data.R"))
source(here("simple_cnn", "mlp", "mlr3torch", "instantiate_learner.R"))
source(here("simple_cnn", "mlp", "mlr3torch", "train_learner.R"))
learner_mlr3torch_mlp$train(tsk_gtcorr)
learner_mlr3torch_mlp$train(tsk_gtcorr)
learner_mlr3torch_mlp
learner_mlr3torch_mlp
names(learner_mlr3torch_mlp)
learner_mlr3torch_mlp$model
learner_mlr3torch_mlp
learner_mlr3torch_mlp$train(tsk_gtcorr)
tsk_gtocrr
names(tsk_gtcorr)
library(here)
start_time_mlr3torch = proc.time()
source(here("simple_cnn", "mlp", "mlr3torch", "set_up_data.R"))
source(here("simple_cnn", "mlp", "mlr3torch", "instantiate_learner.R"))
source(here("simple_cnn", "mlp", "mlr3torch", "train_learner.R"))
tsk_Gtcorr
tsk_gtcorr
summary(tsk_gtcorr)
tsk_gtcorr$head
tsk_gtcorr$head()
tsk_gtcorr$target_names
tsk_gtcorr$feature_names
tsk_gtcorr$row_ids
learner_mlr3torch_mlp = lrn("regr.mlp",
# defining network parameters
activation     = nn_relu,
neurons        = c(20, 20),
# training parameters
batch_size     = 10,
epochs         = n_epochs,
device         = "cpu",
# Defining the optimizer, loss, and callbacks
optimizer      = t_opt("adam", lr = 0.1),
loss           = t_loss("mse"),
callbacks      = t_clbk("history"), # this saves the history in the learner
# Measures to track
measures_valid = msrs(c("regr.mse")),
measures_train = msrs(c("regr.mse")),
# predict type (required by logloss)
predict_type = "response"
)
learner_mlr3torch_mlp
learner_mlr3torch_mlp$train(tsk_gtcorr)
lt
lt[[1]]
lt[1]
lt[1]
lt
class(lt)
lt[[1]]
class(lt[[1]])
lt
lt[1]
lt[1] |> class()
